{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berchie-Sam/Glaucoma_Detection/blob/main/%5Bfinal_project%5DGlaucomaDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-XNB-U_ecJz"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing libraries and packages**"
      ],
      "metadata": {
        "id": "hveRFeDy-bu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYK7CBGJPbOB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Reshape, AveragePooling2D, Dense, ReLU, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras import activations\n",
        "from keras import utils\n",
        "import joblib\n",
        "import math\n",
        "from multiprocessing import Pool\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import KFold\n",
        "from keras import initializers\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "import seaborn as sns\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUMgIm_hLAjI"
      },
      "source": [
        "# 1. **Loading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PRnYM8DQ53-"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osEYS2kiLSDQ"
      },
      "source": [
        "\n",
        "\n",
        "> a) Accessing TPU runtime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4lqPp-NIa5W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check if the TPU system has already been initialized\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)\n",
        "else:\n",
        "    strategy = tf.distribute.OneDeviceStrategy('GPU:0')  # Use GPU if TPU is not available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08iOXQLjQUYE"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/[cleaned]RIM_ONE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbnUQfIMwns"
      },
      "source": [
        "#**EXPLORATORY DATA ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awVkgcAhGTLv"
      },
      "outputs": [],
      "source": [
        "# get the list of png files from sub image class folders\n",
        "with strategy.scope():\n",
        "  # get the list of png files from sub image class folders\n",
        "  normal_imgs = [fn for fn in os.listdir(os.path.join(data_dir, 'Normal')) if (fn.endswith('.png'))]\n",
        "  glaucoma_imgs = [fn for fn in os.listdir(os.path.join(data_dir, 'Glaucoma')) if (fn.endswith('.png'))]\n",
        "\n",
        "  # Check if the lists are empty\n",
        "  if len(normal_imgs) == 0 or len(glaucoma_imgs) == 0:\n",
        "      raise ValueError(\"No images found in the specified directories.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs-Z5VBI3Gip"
      },
      "outputs": [],
      "source": [
        "# Calculate the total number of images\n",
        "total_images = len(normal_imgs) + len(glaucoma_imgs)\n",
        "\n",
        "# Print the total number of images\n",
        "print(\"Total number of images:\", total_images)\n",
        "\n",
        "# Print the number of images in each class\n",
        "print(\"Number of Normal images:\", len(normal_imgs))\n",
        "print(\"Number of Glaucoma images:\", len(glaucoma_imgs))\n",
        "print('')\n",
        "\n",
        "# Define class labels and counts\n",
        "class_labels = ['Normal', 'Glaucoma']\n",
        "class_counts = [len(normal_imgs), len(glaucoma_imgs)]\n",
        "\n",
        "# Create a bar plot for the image distribution\n",
        "plt.bar(class_labels, class_counts)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Image Distribution by Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# randomly select 3 of each\n",
        "select_norm = np.random.choice(normal_imgs, 3, replace=False)\n",
        "select_glau = np.random.choice(glaucoma_imgs, 3, replace=False)\n",
        "\n",
        "# plotting 2 x 3 image matrix\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "for i in range(6):\n",
        "    if i < 3:\n",
        "        fp = os.path.join(data_dir, 'Normal', select_norm[i])\n",
        "        label = 'Normal'\n",
        "    else:\n",
        "        fp = os.path.join(data_dir, 'Glaucoma', select_glau[i-3])\n",
        "        label = 'Glaucoma'\n",
        "    ax = fig.add_subplot(2, 3, i + 1)\n",
        "\n",
        "    # Load the image using PIL (Pillow) without converting to grayscale\n",
        "    fn = Image.open(fp)\n",
        "    plt.imshow(fn)  # Display the image in its original color\n",
        "    plt.title(label)\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tCThtv_j28oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also check the number of files here\n",
        "len(normal_imgs), len(glaucoma_imgs)\n",
        "\n",
        "def img2np(path, list_of_filename, size=(64, 64)):\n",
        "    # iterating through each file\n",
        "    for fn in list_of_filename:\n",
        "        fp = os.path.join(path, fn)\n",
        "        current_image = Image.open(fp).convert(\"L\")  # Load as grayscale\n",
        "        current_image = current_image.resize(size)\n",
        "        # covert image to a matrix\n",
        "        img_ts = np.array(current_image)\n",
        "        # turn that into a vector / 1D array\n",
        "        img_ts = [img_ts.ravel()]\n",
        "        try:\n",
        "            # concatenate different images\n",
        "            full_mat = np.concatenate((full_mat, img_ts))\n",
        "        except UnboundLocalError:\n",
        "            # if not assigned yet, assign one\n",
        "            full_mat = img_ts\n",
        "    return full_mat\n",
        "\n",
        "normal_images = img2np(os.path.join(data_dir, 'Normal'), select_norm)\n",
        "glaucoma_images = img2np(os.path.join(data_dir, 'Glaucoma'), select_glau)\n"
      ],
      "metadata": {
        "id": "_aoB9_ub3B8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def find_mean_img(full_mat, title, size = (64, 64)):\n",
        "    # calculate the average\n",
        "    mean_img = np.mean(full_mat, axis = 0)\n",
        "    # reshape it back to a matrix\n",
        "    mean_img = mean_img.reshape(size)\n",
        "    plt.imshow(mean_img, vmin=0, vmax=255, cmap='Greys_r')\n",
        "    plt.title(f'Mean {title}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    return mean_img\n",
        "\n",
        "norm_mean = find_mean_img(normal_images, 'Normal')\n",
        "glau_mean = find_mean_img(glaucoma_images, 'Glaucoma')"
      ],
      "metadata": {
        "id": "B2M2n17P3FSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbfO8etaOUHv"
      },
      "outputs": [],
      "source": [
        "\n",
        "contrast_mean = norm_mean - glau_mean\n",
        "plt.imshow(contrast_mean, cmap='bwr')\n",
        "plt.title(f'Contrast Mean (Normal vs Glaucoma Mean)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwKnaVMbLcPl"
      },
      "source": [
        "# 2. **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNph-KBLqQr"
      },
      "source": [
        "\n",
        "\n",
        "> a) Image Augmentation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39tIutpMQkif"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    batch_size = 48\n",
        "    Augment_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=12,\n",
        "        height_shift_range=12,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=[0.8, 1.2],\n",
        "        horizontal_flip=True,\n",
        "        rescale=1./255,\n",
        "        fill_mode='nearest'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FeEgpZa42bi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with strategy.scope():\n",
        "  # Determine the target number of samples to balance classes\n",
        "  target_num_samples = 141\n",
        "\n",
        "  # Count the number of samples in each class\n",
        "  normal_dir = os.path.join(data_dir, 'Normal')\n",
        "  glaucoma_dir = os.path.join(data_dir, 'Glaucoma')\n",
        "\n",
        "  # Get the filenames of the original 'normal' and 'glaucoma' images\n",
        "  normal_filenames = [os.path.join(normal_dir, fname) for fname in os.listdir(normal_dir)]\n",
        "  glaucoma_filenames = [os.path.join(glaucoma_dir, fname) for fname in os.listdir(glaucoma_dir)]\n",
        "\n",
        "  num_samples_normal = len(normal_filenames)\n",
        "  num_samples_glaucoma = len(glaucoma_filenames)\n",
        "\n",
        "  num_additional_samples_normal = target_num_samples #- num_samples_normal\n",
        "  num_additional_samples_glaucoma = target_num_samples #- num_samples_glaucoma\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-f8kZ7Z5j0o"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with strategy.scope():\n",
        "\n",
        "  if num_additional_samples_glaucoma > 0:\n",
        "      # Load the images from the 'glaucoma' class\n",
        "      glaucoma_images = [tf.keras.preprocessing.image.load_img(fname, target_size=(256, 256)) for fname in glaucoma_filenames]\n",
        "\n",
        "      # Convert images to numpy arrays\n",
        "      glaucoma_images = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in glaucoma_images])\n",
        "\n",
        "      glau_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/[augmented]RIMONE-DL_dataset/Glaucoma'\n",
        "\n",
        "      # Create a data generator for the 'glaucoma' class with augmentation\n",
        "      glaucoma_datagen = Augment_generator.flow(glaucoma_images,\n",
        "                                        batch_size=batch_size,\n",
        "                                        save_to_dir=glau_dir,\n",
        "                                        save_prefix='augmented',\n",
        "                                        save_format='png',\n",
        "                                        shuffle=True)\n",
        "\n",
        "      # Generate augmented images to increase the number of samples in the 'glaucoma' class\n",
        "      num_batches_to_generate_glaucoma = int(np.ceil(num_additional_samples_glaucoma / batch_size))\n",
        "      remaining_samples_glaucoma = target_num_samples - num_samples_glaucoma\n",
        "\n",
        "      for _ in range(num_batches_to_generate_glaucoma):\n",
        "          if remaining_samples_glaucoma > batch_size:\n",
        "              augmented_images_batch = next(glaucoma_datagen)\n",
        "              remaining_samples_glaucoma -= batch_size\n",
        "          else:\n",
        "              augmented_images_batch = next(glaucoma_datagen)[:remaining_samples_glaucoma]\n",
        "\n",
        "      # Concatenate the augmented images to the original images\n",
        "      glaucoma_images = np.concatenate((glaucoma_images, augmented_images_batch), axis=0)\n",
        "      '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atXym7lK45tJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with strategy.scope():\n",
        "  if num_additional_samples_normal > 0:\n",
        "    # Load the images from the 'normal' class\n",
        "    normal_images = [tf.keras.preprocessing.image.load_img(fname, target_size=(256, 256)) for fname in normal_filenames]\n",
        "\n",
        "    # Convert images to numpy arrays\n",
        "    normal_images = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in normal_images])\n",
        "\n",
        "    norm_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/[augmented]RIMONE-DL_dataset/Normal'\n",
        "\n",
        "    # Create a data generator for the 'normal' class with augmentation\n",
        "    normal_datagen = Augment_generator.flow(normal_images,\n",
        "                                    batch_size=batch_size,\n",
        "                                    save_to_dir=norm_dir,\n",
        "                                    save_prefix='augmented',\n",
        "                                    save_format='png',\n",
        "                                    shuffle=True)\n",
        "\n",
        "    # Generate augmented images to increase the number of samples in the 'normal' class\n",
        "    num_batches_to_generate_normal = int(np.ceil(num_additional_samples_normal / batch_size))\n",
        "    remaining_samples_normal = target_num_samples - num_samples_normal\n",
        "\n",
        "    for _ in range(num_batches_to_generate_normal):\n",
        "        if remaining_samples_normal > batch_size:\n",
        "            augmented_images_batch = next(normal_datagen)\n",
        "            remaining_samples_normal -= batch_size\n",
        "        else:\n",
        "            augmented_images_batch = next(normal_datagen)[:remaining_samples_normal]\n",
        "\n",
        "    # Concatenate the augmented images to the original images\n",
        "    normal_images = np.concatenate((normal_images, augmented_images_batch), axis=0)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLTLWCee66YX"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with strategy.scope():\n",
        "  # Update the total number of images and samples in each class after augmentation\n",
        "  total_images_normal = normal_images.shape[0]\n",
        "  total_images_glaucoma = glaucoma_images.shape[0]\n",
        "  print(\"Total number of images in 'normal' (after augmentation): \", total_images_normal)\n",
        "  print(\"Total number of images in 'glaucoma' (after augmentation): \", total_images_glaucoma)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lz64rXu6ukm"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define a custom data generator function that processes images on-the-fly\n",
        "def custom_data_generator(generator, num_classes):\n",
        "    for batch_images, batch_labels in generator:\n",
        "        for i in range(len(batch_images)):\n",
        "            gray_img = cv2.cvtColor(batch_images[i], cv2.COLOR_BGR2GRAY)\n",
        "            gray_img = cv2.bilateralFilter(gray_img, 9, 75, 75)\n",
        "\n",
        "            # Normalize the grayscale image\n",
        "            normalized_img = cv2.normalize(gray_img, None, 0, 255, cv2.NORM_MINMAX)\n",
        "            normalized_img = normalized_img.astype('uint8')\n",
        "\n",
        "            # Apply CLAHE to the normalized and denoised grayscale image\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            clahe_img = clahe.apply(normalized_img)\n",
        "\n",
        "            # Convert the CLAHE-enhanced image from grayscale to RGB\n",
        "            clahe_rgb_img = cv2.cvtColor(clahe_img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "            yield clahe_rgb_img, batch_labels[i]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDbE7zS78cEg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the ImageDataGenerator and train_generator\n",
        "with strategy.scope():\n",
        "    dir = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/[augmented]RIMONE-DL_dataset'\n",
        "    generator = ImageDataGenerator(rescale=1./255)\n",
        "    train_generator = generator.flow_from_directory(\n",
        "          dir,\n",
        "          target_size=(256, 256),\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    num_batches = len(train_generator)\n",
        "    print('Number of batches: ', num_batches)\n",
        "\n",
        "    images_per_batch = train_generator.batch_size\n",
        "    print('Images per batch: ', images_per_batch)\n",
        "\n",
        "    num_classes = train_generator.num_classes\n",
        "    print(\"Number of classes: \", num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    # Count the number of images in each class\n",
        "    class_indices = train_generator.classes\n",
        "    image_counts_per_class = dict(Counter(class_indices))\n",
        "\n",
        "    print(\"**Number of images per class**\")\n",
        "    total_images = 0\n",
        "    for class_index in range(num_classes):\n",
        "        class_name = list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(class_index)]\n",
        "        class_count = image_counts_per_class[class_index]\n",
        "        total_images += class_count\n",
        "        print(f\"Class '{class_name}': {class_count} images\")\n",
        "\n",
        "    print('Total number of images:', total_images)\n",
        "    num_samples = total_images\n",
        "\n",
        "    # Plot the distribution of images per class\n",
        "    plt.bar(image_counts_per_class.keys(), image_counts_per_class.values())\n",
        "    plt.xticks(range(num_classes), [list(train_generator.class_indices.keys())[i] for i in range(num_classes)], rotation=45)\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Distribution of Images per Class')\n",
        "    plt.show()\n",
        "\n",
        "    # Create a custom data generator\n",
        "    custom_gen = custom_data_generator(train_generator, num_classes)\n",
        "\n",
        "    # Process and retrieve the next batch of images and labels\n",
        "    batch_images, batch_labels = next(custom_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with strategy.scope():\n",
        "  # Function to plot three samples from each class\n",
        "  def plot_samples_per_class(custom_gen, class_names, num_samples=3):\n",
        "      samples_per_class = {class_name: [] for class_name in class_names}\n",
        "\n",
        "      # Collect samples from each class\n",
        "      while any(len(samples) < num_samples for samples in samples_per_class.values()):\n",
        "          image, label = next(custom_gen)\n",
        "          class_name = class_names[np.argmax(label)]  # Get the class name\n",
        "\n",
        "          if len(samples_per_class[class_name]) < num_samples:\n",
        "              samples_per_class[class_name].append(image)\n",
        "\n",
        "      # Plot the collected samples\n",
        "      num_classes = len(class_names)\n",
        "      fig, axes = plt.subplots(num_samples, num_classes, figsize=(15, 8))\n",
        "\n",
        "      for class_idx, class_name in enumerate(class_names):\n",
        "          for sample_idx in range(num_samples):\n",
        "              if sample_idx < len(samples_per_class[class_name]):\n",
        "                  axes[sample_idx, class_idx].imshow(samples_per_class[class_name][sample_idx])\n",
        "                  axes[sample_idx, class_idx].set_title(f\"{class_name}\")\n",
        "                  axes[sample_idx, class_idx].axis('off')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  # Get the class names from the generator\n",
        "  class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "  # Call the function to plot three samples from each class\n",
        "  plot_samples_per_class(custom_gen, class_names)\n"
      ],
      "metadata": {
        "id": "6-gerBDFxl8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4SKKATyJRfU"
      },
      "source": [
        "# 3. **Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to extract features and labels from images\n",
        "def extract_features_and_labels(generator, num_batches, num_samples, height, width, channels):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "        batch_images, batch_labels = next(generator)\n",
        "        features.append(batch_images)\n",
        "        labels.append(batch_labels)\n",
        "\n",
        "    # Concatenate all batches of images and labels\n",
        "    features = np.concatenate(features, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "    # Reshape the features for processing\n",
        "    features = features.reshape(num_samples, height, width, channels)\n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "fYADNUyFmx3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqTIeAGCYIdG"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    height, width = 256, 256\n",
        "    channels = 3\n",
        "\n",
        "    # Extract features from the generator\n",
        "    processed_images, labels = extract_features_and_labels(train_generator, num_batches, num_samples, height, width, channels)\n",
        "\n",
        "    # Normalize the extracted features\n",
        "    scaler = StandardScaler()\n",
        "    normalized_features = scaler.fit_transform(processed_images.reshape(-1, height * width * channels))\n",
        "\n",
        "    normalized_features = normalized_features.reshape(num_samples, height, width, channels)\n",
        "    print(\"Shape of normalized features: \", normalized_features.shape)\n",
        "\n",
        "    # Print the shape of labels\n",
        "    print(\"Shape of labels: \", labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8WLpoS1RADO"
      },
      "source": [
        "# 4. **Splitting of data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGzjirQWJVG-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "with strategy.scope():\n",
        "    X = normalized_features\n",
        "    y = labels\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=23)\n",
        "\n",
        "    if len(X) >= kf.n_splits:\n",
        "        for train_index, test_index in kf.split(X):\n",
        "\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            # Further split the test set into test and validation sets\n",
        "            X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=23)\n",
        "    else:\n",
        "        print(\"Not enough samples in the dataset to perform KFold cross-validation.\")\n",
        "\n",
        "\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"X_val shape:\", X_val.shape)\n",
        "    print(\"X_test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFx-USmaICOy"
      },
      "source": [
        "# **CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUy3F8igFkBs"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name = 'Block1_Conv1', input_shape=input_shape))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name = 'Block1_Conv2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name = 'Block1_Pool'))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name = 'Block2_Conv1'))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name = 'Block2_Conv2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name = 'Block2_Pool'))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name = 'Block3_Conv1'))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name = 'Block3_Conv2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name = 'Block3_Pool'))\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name = 'Block4_Conv1'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name = 'Block4_Pool'))\n",
        "    model.add(Dropout(0.25, name = 'Block4_Dropout'))\n",
        "\n",
        "    model.add(Flatten(name = 'Flatten'))\n",
        "    model.add(Dropout(0.5, name = 'Dropout'))\n",
        "    model.add(Dense(units=num_classes, activation='sigmoid', name = 'Output'))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4VBUmS0I1wd"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Defines the input shape\n",
        "  input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "  cnn_model = create_cnn_model(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxI8CdSSN8jx"
      },
      "outputs": [],
      "source": [
        "\n",
        "with strategy.scope():\n",
        "  # Compile the model\n",
        "  cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
        "\n",
        "  # Model summary\n",
        "  cnn_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85mhr1dYTTxd"
      },
      "outputs": [],
      "source": [
        "\n",
        "with strategy.scope():\n",
        "  vis = visualkeras.layered_view(cnn_model, scale_xy=1, scale_z=1, max_z=100, legend = True)\n",
        "  vis.show()\n",
        "  # Save the visualization as an image\n",
        "  plt.savefig('model.png', format='png', bbox_inches='tight', pad_inches=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrvC2N1gI3eI"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Define the directory to save the model checkpoints\n",
        "  checkpoint_dir = '/content/drive/MyDrive/Model_Checkpoints/Projects/Glaucoma_Detection'\n",
        "\n",
        "  # Ensure the directory exists\n",
        "  os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRP7atfmuPBD"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ValidationAccuracyStopCallback(Callback):\n",
        "    def __init__(self, target_accuracy):\n",
        "        super(ValidationAccuracyStopCallback, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_accuracy') >= self.target_accuracy:\n",
        "            print(f\"Stopping training as val_accuracy reached {self.target_accuracy}% or above.\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zDyqWLbugVe"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Define the custom validation accuracy stopping callback\n",
        "    target_accuracy = 1.0\n",
        "    val_accuracy_stop = ValidationAccuracyStopCallback(target_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ODkTFhoN_mR"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Define the EarlyStopping callback\n",
        "  early_stop = EarlyStopping(monitor='accuracy', patience=10, verbose=1, mode='max')\n",
        "  epochs = 50\n",
        "\n",
        "  # Create ModelCheckpoint callback for CNN model\n",
        "  cnn_checkpoint_path = os.path.join(checkpoint_dir, 'cnn_model_checkpoint.h5')\n",
        "  cnn_model_checkpoint = ModelCheckpoint(cnn_checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "  # Train the model on the training set\n",
        "  CNN_history = cnn_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks = cnn_model_checkpoint)#early_stop, val_accuracy_stop,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddhUF6NSIJaA"
      },
      "source": [
        "# **CAPSULE NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88IkfZTZD-3j"
      },
      "outputs": [],
      "source": [
        "def squash(x, axis=-1, keepdims=True):\n",
        "    squared_norm = tf.reduce_sum(tf.square(x), axis=axis, keepdims=keepdims)\n",
        "    scale = squared_norm / (1 + squared_norm) / tf.sqrt(squared_norm + tf.keras.backend.epsilon())\n",
        "    return scale * x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "396I0rfYbgiN"
      },
      "outputs": [],
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    margin = 0.5\n",
        "    margin_positive = K.square(K.relu(1 - margin - y_pred))\n",
        "    loss = K.sum(y_true * margin_positive, axis=-1)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDKf9oQsMlTF"
      },
      "outputs": [],
      "source": [
        "class Class_Capsule(layers.Layer):\n",
        "    \"\"\"\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    :param share_weights: whether to share weights among capsules\n",
        "    :param kernel_initializer: initializer for the kernel weights\n",
        "    :param activation: activation function for the output vectors\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3, share_weights=False,\n",
        "                 kernel_initializer='glorot_uniform', activation='squash', **kwargs):\n",
        "        super(Class_Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3\n",
        "        input_num_capsule = input_shape[1]\n",
        "        input_dim_capsule = input_shape[2]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(name='capsule_kernel',\n",
        "                                          shape=(1, input_dim_capsule, self.num_capsule * self.dim_capsule),\n",
        "                                          initializer=self.kernel_initializer,\n",
        "                                          trainable=True)\n",
        "        else:\n",
        "            self.kernel = self.add_weight(name='capsule_kernel',\n",
        "                                          shape=(input_num_capsule, input_dim_capsule,\n",
        "                                                 self.num_capsule * self.dim_capsule),\n",
        "                                          initializer=self.kernel_initializer,\n",
        "                                          trainable=True)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, self.num_capsule, input_num_capsule, self.dim_capsule))\n",
        "\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, 0, :])\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # # # Simplified routing # # #\n",
        "        norm_hat_inputs = tf.norm(hat_inputs, axis=-1)\n",
        "        weighted_hat_inputs = hat_inputs * tf.expand_dims(norm_hat_inputs, axis=-1)\n",
        "        o = K.sum(weighted_hat_inputs, axis=2) / self.dim_capsule\n",
        "        o = self.activation(o)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(Class_Capsule, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeKFBaBemJ2S"
      },
      "outputs": [],
      "source": [
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikXBw0k-FQkU"
      },
      "outputs": [],
      "source": [
        "\n",
        "with strategy.scope():\n",
        "    # Get the output of the third convolutional layer\n",
        "    cnn_output = cnn_model.layers[11].output\n",
        "    x = Conv2D(filters=128, kernel_size=(7, 7), activation='relu', name='Block5_Conv1')(cnn_output)\n",
        "    x = Conv2D(filters=128, kernel_size=(6, 6), activation='relu', name='Block5_Conv2')(x)\n",
        "\n",
        "    # Primary Capsule\n",
        "    x = PrimaryCap(x, dim_capsule=16, n_channels=2, kernel_size=2, strides=2, padding='valid')\n",
        "\n",
        "    # Class Capsule Layer\n",
        "    capsule = Class_Capsule(num_classes, 16, 4, kernel_initializer='glorot_uniform')(x)\n",
        "\n",
        "    Caps_output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=2)))(capsule)\n",
        "\n",
        "    CapsNet_model = Model(inputs=cnn_model.input, outputs=Caps_output)\n",
        "\n",
        "    # Using margin loss\n",
        "    optimizer = Adam(learning_rate=1e-4) #(0.0001)\n",
        "    CapsNet_model.compile(loss=margin_loss, optimizer=optimizer, metrics='accuracy')\n",
        "    CapsNet_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdb0dD3fEVBM"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Create ModelCheckpoint callback for CapsNet model\n",
        "  CapsNet_checkpoint_path = os.path.join(checkpoint_dir, 'CapsNet_model_checkpoint.h5')\n",
        "  CapsNet_model_checkpoint = ModelCheckpoint(CapsNet_checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "  # Train the model on the training set\n",
        "  CapsNet_history = CapsNet_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks = CapsNet_model_checkpoint) #early_stop, val_accuracy_stop,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-iVPm0U_5Ah"
      },
      "source": [
        "#**GABOR CAPSULE NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUqtOfcOAEep"
      },
      "outputs": [],
      "source": [
        "class GaborLayer(Layer):\n",
        "    def __init__(self, filters, kernel_size, strides=(1, 1), activation=None, **kwargs):\n",
        "        super(GaborLayer, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_channels = input_shape[-1]\n",
        "        self.kernels_real, self.kernels_imag = self._create_gabor_kernels(input_channels)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Perform convolution with complex Gabor filters\n",
        "        conv_real = K.conv2d(inputs, self.kernels_real, strides=self.strides, padding='valid')\n",
        "        conv_imag = K.conv2d(inputs, self.kernels_imag, strides=self.strides, padding='valid')\n",
        "\n",
        "        # Combine real and imaginary parts\n",
        "        output = K.sqrt(K.square(conv_real) + K.square(conv_imag))\n",
        "\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.filters\n",
        "        return tuple(output_shape)\n",
        "\n",
        "    def _create_gabor_kernels(self, input_channels):\n",
        "        kernels_real = []\n",
        "        kernels_imag = []\n",
        "\n",
        "        # Generate Gabor filters\n",
        "        for _ in range(self.filters):\n",
        "            kernel_real, kernel_imag = self._generate_gabor_filter(self.kernel_size, input_channels)\n",
        "            kernels_real.append(kernel_real)\n",
        "            kernels_imag.append(kernel_imag)\n",
        "\n",
        "        # Stack filters along the channel dimension\n",
        "        kernels_real = K.stack(kernels_real, axis=-1)\n",
        "        kernels_imag = K.stack(kernels_imag, axis=-1)\n",
        "\n",
        "        return kernels_real, kernels_imag\n",
        "\n",
        "    def _generate_gabor_filter(self, kernel_size, input_channels):\n",
        "        # Create Gabor filter parameters\n",
        "        sigma = 0.56 * ((kernel_size[0] - 1) * 0.5 - 1) + 0.25\n",
        "        theta = np.random.uniform(0, np.pi)\n",
        "        lambda_ = np.random.uniform(0.5, kernel_size[0] - 0.5)\n",
        "        psi = np.random.uniform(0, np.pi)\n",
        "        gamma = np.random.uniform(0.5, 1)\n",
        "\n",
        "        # Generate Gabor filter\n",
        "        x0 = (kernel_size[0] - 1) // 2\n",
        "        y0 = (kernel_size[1] - 1) // 2\n",
        "\n",
        "        y, x = np.mgrid[-x0:x0 + 1, -y0:y0 + 1]\n",
        "        distance_from_center = np.sqrt(x**2 + y**2)\n",
        "        mask = np.where(distance_from_center <= min(x0, y0), 1.0, 0.0)\n",
        "\n",
        "        x_theta = x * np.cos(theta) + y * np.sin(theta)\n",
        "        y_theta = -x * np.sin(theta) + y * np.cos(theta)\n",
        "\n",
        "        kernel_real = mask * np.exp(-0.5 * (x_theta ** 2 + gamma ** 2 * y_theta ** 2) / sigma ** 2) \\\n",
        "                      * np.cos(2 * np.pi * x_theta / lambda_ + psi)\n",
        "        kernel_imag = mask * np.exp(-0.5 * (x_theta ** 2 + gamma ** 2 * y_theta ** 2) / sigma ** 2) \\\n",
        "                      * np.sin(2 * np.pi * x_theta / lambda_ + psi)\n",
        "\n",
        "        # Reshape the kernels to match the input channel dimensions\n",
        "        kernel_real = kernel_real.reshape((kernel_size[0], kernel_size[1], 1))\n",
        "        kernel_imag = kernel_imag.reshape((kernel_size[0], kernel_size[1], 1))\n",
        "\n",
        "        # Repeat the kernels for each input channel\n",
        "        kernel_real = np.repeat(kernel_real, input_channels, axis=-1)\n",
        "        kernel_imag = np.repeat(kernel_imag, input_channels, axis=-1)\n",
        "\n",
        "        # Convert the kernels to tensors\n",
        "        kernel_real = K.constant(kernel_real, dtype=K.floatx())\n",
        "        kernel_imag = K.constant(kernel_imag, dtype=K.floatx())\n",
        "\n",
        "        return kernel_real, kernel_imag\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"filters\": self.filters,\n",
        "            \"kernel_size\": self.kernel_size,\n",
        "            \"strides\": self.strides,\n",
        "            \"activation\": self.activation,\n",
        "         })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2hYmuJgEsLq"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Get the output of the third convolutional layer\n",
        "  cnn_output = cnn_model.layers[11].output\n",
        "  x = Conv2D(filters=128, kernel_size=(7, 7), activation='relu', name='Block5_Conv1')(cnn_output)\n",
        "  print('X: ', x.shape)\n",
        "\n",
        "  gabor_layer = GaborLayer(filters=128, kernel_size=(5, 5), strides=(1, 1), activation=K.relu, name='GaborLayer')(x)\n",
        "\n",
        "  #Primary Capsule\n",
        "  x = PrimaryCap(gabor_layer, dim_capsule=16, n_channels=2, kernel_size=2, strides=2, padding='valid')\n",
        "\n",
        "  # Secondary Capsule Layer\n",
        "  capsule = Class_Capsule(num_classes, 16, 4, True)(x)\n",
        "  Caps_output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), axis=2)))(capsule)\n",
        "\n",
        "  # Create the combined model\n",
        "  GCN_model = Model(inputs=cnn_model.input, outputs=Caps_output)\n",
        "\n",
        "  # Using margin loss\n",
        "  optimizer = Adam(learning_rate=1e-4) #(0.0001)\n",
        "\n",
        "  # Compile the model\n",
        "  GCN_model.compile(loss=margin_loss, optimizer=optimizer, metrics='accuracy')\n",
        "\n",
        "  # Model summary\n",
        "  GCN_model.summary() #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEBCfwbprqcm"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AccuracyStopCallback(Callback):\n",
        "    def __init__(self, target_accuracy):\n",
        "        super(AccuracyStopCallback, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('accuracy') >= self.target_accuracy:\n",
        "            print(f\"Stopping training as val_accuracy reached {self.target_accuracy}% or above.\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml0sgeL0rqcm"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Define the custom validation accuracy stopping callback\n",
        "    target_accuracy = 1.0\n",
        "    accuracy_stop = AccuracyStopCallback(target_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU7Ev1GYAjyW"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Create ModelCheckpoint callback for CapsNet model\n",
        "  GCN_checkpoint_path = os.path.join(checkpoint_dir, 'GCN_model_checkpoint.h5')\n",
        "  GCN_model_checkpoint = ModelCheckpoint(GCN_checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "  # Train the model on the training set\n",
        "  GCN_history = GCN_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[val_accuracy_stop, GCN_model_checkpoint]) #early_stop, accuracy_stop,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Class Activation Maps**"
      ],
      "metadata": {
        "id": "dFNVUJOn-unb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha56FwDHifbx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the function to generate class activation maps using Grad-CAM\n",
        "def generate_cam(model, img, class_index, layer_name):\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    grad_model = Model(inputs=model.inputs, outputs=(model.get_layer(layer_name).output, model.output))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_output, predictions = grad_model(img)\n",
        "        class_output = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(class_output, conv_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_output = conv_output[0].numpy()\n",
        "\n",
        "    for i in range(conv_output.shape[-1]):\n",
        "        conv_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(conv_output, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    return heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSmg9kaaipFg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert data_dir to a string\n",
        "data_dir = str(data_dir)\n",
        "\n",
        "# Get image filenames for each class\n",
        "normal_img = [fn for fn in os.listdir(os.path.join(data_dir, 'Normal')) if fn == 'r1_Im037.png']\n",
        "glaucoma_img = [fn for fn in os.listdir(os.path.join(data_dir, 'Glaucoma')) if fn == 'r2_Im270.png']\n",
        "\n",
        "# Combine the image filenames for both classes\n",
        "image_filenames = normal_img + glaucoma_img\n",
        "\n",
        "# Get class indices and names\n",
        "class_indices = {'Normal': 0, 'Glaucoma': 1}\n",
        "class_names = list(class_indices.keys())\n",
        "\n",
        "# Generate Grad-CAM for one image from each class\n",
        "for image_filename in image_filenames:\n",
        "    # Determine the class based on the image filename\n",
        "    class_name = 'Glaucoma' if image_filename in glaucoma_img else 'Normal'\n",
        "    class_index = class_indices[class_name]\n",
        "\n",
        "    # Find the full image path\n",
        "    image_path = os.path.join(data_dir, class_name, image_filename)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (X_train.shape[1], X_train.shape[2]))\n",
        "    img = img / 255.0  # Normalize the image\n",
        "\n",
        "    print('Class index: ', class_index)\n",
        "\n",
        "    # Generate CAM for CNN model\n",
        "    cam_cnn = generate_cam(cnn_model, img, class_index, 'Block4_Conv1')\n",
        "\n",
        "    # Generate CAM for CapsNet model\n",
        "    cam_capsnet = generate_cam(CapsNet_model, img, class_index, 'Block5_Conv1')\n",
        "\n",
        "    # Generate CAM for GCN model\n",
        "    cam_gcn = generate_cam(GCN_model, img, class_index, 'Block5_Conv1')\n",
        "\n",
        "   # Ensure the heatmap has non-zero values before normalization\n",
        "    if np.max(cam_cnn) != 0:\n",
        "        cam_cnn /= np.max(cam_cnn)\n",
        "    else:\n",
        "        cam_cnn = np.zeros_like(cam_cnn)\n",
        "\n",
        "\n",
        "    if np.max(cam_capsnet) != 0:\n",
        "        cam_capsnet /= np.max(cam_capsnet)\n",
        "    else:\n",
        "      cam_capsnet = np.zeros_like(cam_capsnet)\n",
        "\n",
        "    if np.max(cam_gcn) != 0:\n",
        "        cam_gcn /= np.max(cam_gcn)\n",
        "    else:\n",
        "      cam_gcn = np.zeros_like(cam_gcn)\n",
        "\n",
        "    # Plot the original image and overlaid CAMs\n",
        "    plt.figure(figsize=(18, 4))\n",
        "    plt.subplot(141)\n",
        "    plt.imshow(img[:, :, ::-1])\n",
        "    plt.title(f'Original Image - {class_name}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(142)\n",
        "    plt.imshow(img[:, :, ::-1])\n",
        "    plt.imshow(cam_cnn, cmap='jet', alpha=0.5)\n",
        "    plt.title(f'CNN CAM - {class_name}')\n",
        "\n",
        "    plt.subplot(143)\n",
        "    plt.imshow(img[:, :, ::-1])\n",
        "    plt.imshow(cam_capsnet, cmap='jet', alpha=0.5)\n",
        "    plt.title(f'CapsNet CAM - {class_name}')\n",
        "\n",
        "    plt.subplot(144)\n",
        "    plt.imshow(img[:, :, ::-1])\n",
        "    plt.imshow(cam_gcn, cmap='jet', alpha=0.5)\n",
        "    plt.title(f'GCN CAM - {class_name}')\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5AawhmgEHhP"
      },
      "source": [
        "#**EVALUATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VncQjw70ThA"
      },
      "source": [
        "\n",
        "\n",
        "1. Evaluation on Testing set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsE5cK-YoYBa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, hamming_loss, jaccard_score\n",
        "\n",
        "# CNN model evaluation\n",
        "y_pred_cnn = cnn_model.predict(X_test)\n",
        "y_pred_cnn_binary = (y_pred_cnn > 0.5).astype(int)\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "cnn_test_auc_score = roc_auc_score(y_test, y_pred_cnn)\n",
        "\n",
        "# CapsNet model evaluation\n",
        "y_pred_capsnet = CapsNet_model.predict(X_test)\n",
        "y_pred_capsnet_binary = (y_pred_capsnet > 0.5).astype(int)\n",
        "capsnet_test_loss, capsnet_test_acc = CapsNet_model.evaluate(X_test, y_test, verbose=0)\n",
        "capsnet_test_auc_score = roc_auc_score(y_test, y_pred_capsnet)\n",
        "\n",
        "# GCN model evaluation\n",
        "y_pred_gcn = GCN_model.predict(X_test)\n",
        "y_pred_gcn_binary = (y_pred_gcn > 0.5).astype(int)\n",
        "gcn_test_loss, gcn_test_acc = GCN_model.evaluate(X_test, y_test, verbose=0)\n",
        "gcn_test_auc_score = roc_auc_score(y_test, y_pred_gcn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejApjQ-qMrp-"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Plotting accuracies\n",
        "  plt.plot(CNN_history.history['accuracy'], label='Training_CNN', color='blue')\n",
        "  plt.plot(CapsNet_history.history['accuracy'], label='Training_CapsNet', color='green')\n",
        "  plt.plot(GCN_history.history['accuracy'], label='Training_GCN', color='red')\n",
        "  plt.title('Model Accuracies')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ixp78DJM2L2"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # Plotting losses\n",
        "  plt.plot(CNN_history.history['loss'], label='Training_CNN', color='blue')\n",
        "  plt.plot(CapsNet_history.history['loss'], label='Training_CapsNet', color='green')\n",
        "  plt.plot(GCN_history.history['loss'], label='Training_GCN', color='red')\n",
        "  plt.title('Model Losses')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*ROC Curves*"
      ],
      "metadata": {
        "id": "caCeV035-9Nv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re9-nbKczY5c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Plotting ROC curve for class 0\n",
        "fpr, tpr, _ = roc_curve(y_test[:, 0], y_pred_cnn[:, 0])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='CNN', color='blue')\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test[:, 0], y_pred_capsnet[:, 0])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='CapsNet', color='green')\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test[:, 0], y_pred_gcn[:, 0])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='GCN', color='red')\n",
        "\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Results*"
      ],
      "metadata": {
        "id": "OAnc-dtk_Eis"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujUMspO-hc8n"
      },
      "outputs": [],
      "source": [
        "# Print evaluation results\n",
        "print('#----------------------------------------------------------------------------------------#')\n",
        "print('EVALUATION OF MODELS (TESTING)')\n",
        "print('#----------------------------------------------------------------------------------------#')\n",
        "\n",
        "print('1')\n",
        "print('CONVOLUTIONAL NEURAL NETWORK:')\n",
        "print(\"Accuracy:\", cnn_test_acc)\n",
        "print(\"Loss:\", cnn_test_loss)\n",
        "print('AUC Score: ', cnn_test_auc_score)\n",
        "print('')\n",
        "\n",
        "print('2')\n",
        "print('***CAPSULE NETWORK***')\n",
        "print(\"Accuracy:\", capsnet_test_acc)\n",
        "print(\"Loss:\", capsnet_test_loss)\n",
        "print('AUC Score: ', capsnet_test_auc_score)\n",
        "print('')\n",
        "\n",
        "print('3')\n",
        "print('***GABOR CAPSULE NETWORK***')\n",
        "print(\"Accuracy:\", gcn_test_acc)\n",
        "print(\"Loss:\", gcn_test_loss)\n",
        "print('AUC Score: ', gcn_test_auc_score)\n",
        "print('')\n",
        "print('#----------------------------------------------------------------------------------------#')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6TeTw4bPCeh"
      },
      "source": [
        "#*Confusion Matrices*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1FYazBeB6yU"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "    # Get true labels from y_test\n",
        "    y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Convert predictions to labels\n",
        "    y_pred_cnn_labels = np.argmax(y_pred_cnn, axis=1)\n",
        "    y_pred_capsnet_labels = np.argmax(y_pred_capsnet, axis=1)\n",
        "    y_pred_gcn_labels = np.argmax(y_pred_gcn, axis=1)\n",
        "\n",
        "    # Error Analysis\n",
        "    for i in range(0, len(y_test)):\n",
        "        true_label = np.argmax(y_test[i])\n",
        "        cnn_prediction = np.argmax(y_pred_cnn[i])\n",
        "        capsnet_prediction = np.argmax(y_pred_capsnet[i])\n",
        "        gcn_prediction = np.argmax(y_pred_gcn[i])\n",
        "\n",
        "        if true_label != cnn_prediction or true_label != capsnet_prediction or true_label != gcn_prediction:\n",
        "            print(\"True Label:\", true_label)\n",
        "            print(\"CNN Prediction:\", cnn_prediction)\n",
        "            print(\"CapsNet Prediction:\", capsnet_prediction)\n",
        "            print(\"GCN Prediction:\", gcn_prediction)\n",
        "            print(\"---------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTspt5_8RM9-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "# Define a function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.set(font_scale=1.2)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True,  # Set cbar to True\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOrucRk_YHFA"
      },
      "outputs": [],
      "source": [
        "\n",
        "with strategy.scope():\n",
        "  # Plot confusion matrices\n",
        "  classes = [\"Glaucoma\", \"Normal\"]\n",
        "  plot_confusion_matrix(y_true_labels, y_pred_cnn_labels, classes, title='CNN Confusion Matrix')\n",
        "  plot_confusion_matrix(y_true_labels, y_pred_capsnet_labels, classes, title='CapsNet Confusion Matrix')\n",
        "  plot_confusion_matrix(y_true_labels, y_pred_gcn_labels, classes, title='GCN Confusion Matrix')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and specificity separately\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    return precision, recall, specificity"
      ],
      "metadata": {
        "id": "WBaCtpi98bhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "    # Calculate precision, recall, and specificity separately\n",
        "    cnn_precision, cnn_recall, cnn_specificity = calculate_metrics(y_true_labels, y_pred_cnn_labels)\n",
        "    capsnet_precision, capsnet_recall, capsnet_specificity = calculate_metrics(y_true_labels, y_pred_capsnet_labels)\n",
        "    gcn_precision, gcn_recall, gcn_specificity = calculate_metrics(y_true_labels, y_pred_gcn_labels)\n",
        "\n",
        "    # Print precision, recall, and specificity values\n",
        "    print(f'CNN => Precision: {cnn_precision:.4f}, Recall: {cnn_recall:.4f}, Specificity: {cnn_specificity:.4f}')\n",
        "    print(f'CapsNet => Precision: {capsnet_precision:.4f}, Recall: {capsnet_recall:.4f}, Specificity: {capsnet_specificity:.4f}')\n",
        "    print(f'GCN => Precision: {gcn_precision:.4f}, Recall: {gcn_recall:.4f}, Specificity: {gcn_specificity:.4f}')"
      ],
      "metadata": {
        "id": "z64CvdF78ci-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i6TuIgcPLTB"
      },
      "source": [
        "#**Testing and Inferencing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ6oza6EVKUw"
      },
      "outputs": [],
      "source": [
        "# Directory containing the images for inference\n",
        "images_directory = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/ACRIMA_inference'\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((X_train.shape[1], X_train.shape[2]))\n",
        "    image = np.array(image) / 255.0  # Normalize the image\n",
        "    return image\n",
        "\n",
        "# Iterate through all image files in the directory\n",
        "for filename in os.listdir(images_directory):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(images_directory, filename)\n",
        "        test_image = preprocess_image(image_path)\n",
        "\n",
        "        with strategy.scope():\n",
        "            # CNN model classification\n",
        "            cnn_prediction = cnn_model.predict(np.expand_dims(test_image, axis=0))\n",
        "            cnn_prediction_label = np.argmax(cnn_prediction)\n",
        "            cnn_prediction_name = class_names[cnn_prediction_label]\n",
        "\n",
        "            # CapsNet model classification\n",
        "            capsnet_prediction = CapsNet_model.predict(np.expand_dims(test_image, axis=0))\n",
        "            capsnet_prediction_label = np.argmax(capsnet_prediction)\n",
        "            capsnet_prediction_name = class_names[capsnet_prediction_label]\n",
        "\n",
        "            # GCN model classification\n",
        "            gcn_prediction = GCN_model.predict(np.expand_dims(test_image, axis=0))\n",
        "            gcn_prediction_label = np.argmax(gcn_prediction)\n",
        "            gcn_prediction_name = class_names[gcn_prediction_label]\n",
        "\n",
        "        # Display the image\n",
        "        plt.imshow(test_image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Print classifications\n",
        "        print(\"Image:\", filename)\n",
        "        print(\"CNN Model Classification:\", cnn_prediction_name)\n",
        "        print(\"CapsNet Model Classification:\", capsnet_prediction_name)\n",
        "        print(\"GCN Model Classification:\", gcn_prediction_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4tPuCwuPUZT"
      },
      "source": [
        "# **Saving and Converting best model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLN35cmhOTXA"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    drive_path = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/RIMONE-DL_dataset'\n",
        "    file_name = 'best_model.h5'\n",
        "    file_path = os.path.join(drive_path, file_name)\n",
        "\n",
        "    if os.path.isfile(file_path):\n",
        "        print('File exists:', file_path)\n",
        "    else:\n",
        "        print('File does not exist:', file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghnew7lYmeAu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "with strategy.scope():\n",
        "    # Specify the path to save the best model\n",
        "    save_path = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/Saved_Models/model.h5'\n",
        "\n",
        "    # Determine the best model based on a chosen metric (e.g., accuracy and loss)\n",
        "    best_model_name = None\n",
        "    best_accuracy = 0.0\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # Check if the CNN model has the best metric\n",
        "    if cnn_test_acc > best_accuracy and cnn_test_loss < best_loss:\n",
        "        best_accuracy = cnn_test_acc\n",
        "        best_loss = cnn_test_loss\n",
        "        best_model_name = 'CNN model'\n",
        "        save_model(cnn_model, save_path)  # Save the best CNN model\n",
        "\n",
        "    # Check if the CapsNet model has the best metric\n",
        "    if capsnet_test_acc > best_accuracy and capsnet_test_loss < best_loss:\n",
        "        best_accuracy = capsnet_test_acc\n",
        "        best_loss = capsnet_test_loss\n",
        "        best_model_name = 'CapsNet model'\n",
        "        save_model(CapsNet_model, save_path)  # Save the best CapsNet model\n",
        "\n",
        "    # Check if the GCN model has the best metric\n",
        "    if gcn_test_acc > best_accuracy and gcn_test_loss < best_loss:\n",
        "        best_accuracy = gcn_test_acc\n",
        "        best_loss = gcn_test_loss\n",
        "        best_model_name = 'Gabor CapsNet model'\n",
        "        save_model(GCN_model, save_path)  # Save the best GCN model\n",
        "\n",
        "    # Define the path for the labels file\n",
        "    labels_file_path = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/TfLite/labels.txt'\n",
        "\n",
        "    # Save the labels and class names as a .txt file\n",
        "    with open(labels_file_path, 'w') as f:\n",
        "        for class_name, label_idx in train_generator.class_indices.items():\n",
        "            f.write(class_name + '(' + str(label_idx) + ')' + '\\n')\n",
        "\n",
        "    print('Labels and class names saved as .txt:', labels_file_path)\n",
        "\n",
        "# Print the details of the best model\n",
        "print('Best Model:')\n",
        "print('Accuracy:', best_accuracy)\n",
        "print('Loss:', best_loss)\n",
        "print('Model Name:', best_model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G_hpBgylWle"
      },
      "outputs": [],
      "source": [
        "# Path to the saved model in .h5 format\n",
        "saved_model_path = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/Saved_Models/model.h5'\n",
        "\n",
        "# Define the custom objects dictionary for loading custom layers\n",
        "custom_objects = {'Class_Capsule': Class_Capsule, 'margin_loss': margin_loss, 'squash': squash}\n",
        "\n",
        "# Load the saved model with custom layers and loss function\n",
        "model = tf.keras.models.load_model(saved_model_path, custom_objects=custom_objects, compile=False)\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model\n",
        "tflite_model_path = '/content/drive/MyDrive/Colab Notebooks/Projects/Final(Undergraduate)/TfLite/model.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print('Model converted and saved as TensorFlow Lite:', tflite_model_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}